package com.zipline.service.zigbang.crawler;

import com.fasterxml.jackson.databind.JsonNode;
import com.fasterxml.jackson.databind.ObjectMapper;
import com.zipline.domain.entity.enums.CrawlStatus;
import com.zipline.domain.entity.enums.PropertyCategory;
import com.zipline.domain.entity.zigbang.ZigBangArticle;
import com.zipline.domain.entity.zigbang.ZigBangCrawl;
import com.zipline.global.util.GeoHashGenerator;
import com.zipline.global.util.RandomSleepUtil;
import com.zipline.global.util.UrlEncodingUtil;
import com.zipline.infrastructure.crawl.fetch.Fetcher;
import com.zipline.infrastructure.crawl.fetch.dto.FetchConfigDTO;
import com.zipline.infrastructure.zigbang.ZigBangArticleRepository;
import com.zipline.infrastructure.zigbang.ZigBangCrawlRepository;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.stereotype.Service;

import java.util.*;
import java.util.Map;
import java.util.concurrent.CompletableFuture;

@Slf4j
@Service("defaultZigBangArticleCrawler")
@RequiredArgsConstructor
public class DefaultZigBangArticleCrawler implements ZigBangArticleCrawler {

    private final SharedZigbangCrawler shared = new SharedZigbangCrawler();

    private static final int LIMIT = 20;
    private static final int GEOHASH_PRECISION = 5;

    // ëŒ€í•œë¯¼êµ­ ìœ„ë„/ê²½ë„ ë²”ìœ„
    private static final double MIN_LAT = 33.0;
    private static final double MAX_LAT = 38.6;
    private static final double MIN_LON = 124.5;
    private static final double MAX_LON = 132.0;

    // ê²©ì ê°„ê²©
    private static final double LAT_STEP = 0.05;
    private static final double LON_STEP = 0.05;

    private final ObjectMapper objectMapper;
    private final ZigBangCrawlRepository crawlRepo;
    private final ZigBangArticleRepository articleRepo;

    @Override
    public void executeCrawl(Fetcher fetcher) {
        log.info("=== ì§ë°© ì „ì²´ ë§¤ë¬¼ ì •ë³´ ìˆ˜ì§‘ ì‹œì‘ ===");

        Set<String> koreaGeohashes = GeoHashGenerator.generateGeoHashs(
                GEOHASH_PRECISION, MIN_LAT, MAX_LAT, MIN_LON, MAX_LON, LAT_STEP, LON_STEP);

        for (PropertyCategory category : PropertyCategory.values()) {
            for (String geohash : koreaGeohashes) {
                try {
                    if (isAlreadyCompleted(geohash, category)) {
                        log.info("ì´ë¯¸ ì™„ë£Œëœ geohash: {}, category: {}", geohash, category);
                        continue;
                    }

                    List<Long> itemIds = fetchItemIds(fetcher, geohash, category);

                    if (!itemIds.isEmpty()) {
                        fetchAndSaveItemDetails(fetcher, geohash, category, itemIds);
                        updateCrawlComplete(geohash, category);
                    }

                } catch (Exception e) {
                    String errorMsg = String.format("ì§€ì˜¤í•´ì‹œ %s, ì¹´í…Œê³ ë¦¬ %s ì²˜ë¦¬ ì‹¤íŒ¨: %s", geohash, category, e.getMessage());
                    log.error(errorMsg, e);
                    updateCrawlError(geohash, category, errorMsg);
                }
            }
        }

        log.info("=== ì§ë°© ì „ì²´ ë§¤ë¬¼ ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ ===");
    }

    private List<Long> fetchItemIds(Fetcher fetcher, String geohash, PropertyCategory category) throws Exception {
        FetchConfigDTO config = FetchConfigDTO.zigbangDefaultConfig();
        int offset = 0;
        boolean hasMore = true;
        List<Long> itemIds = new ArrayList<>();

        log.info("ì§ë°© ë§¤ë¬¼ ID ìˆ˜ì§‘ ì‹œì‘ - geohash: {}, category: {}", geohash, category);
        ZigBangCrawl crawl = ZigBangCrawl.create(geohash, category).updateStatus(CrawlStatus.PROCESSING);
        crawlRepo.save(crawl);

        while (hasMore) {
            String listUrl = buildListUrl(category, geohash) + "&offset=" + offset + "&limit=" + LIMIT;
            String response = fetcher.fetch(listUrl, config);

            if (response != null && !response.isEmpty()) {
                List<Long> ids = parseItemIdsFromResponse(response);
                itemIds.addAll(ids);
                hasMore = checkHasMore(response);
                offset += LIMIT;
            } else {
                log.warn("ì§€ì˜¤í•´ì‹œ {} / ì¹´í…Œê³ ë¦¬ {} ìš”ì²­ ì‹¤íŒ¨ â†’ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ëŒ€ì²´", geohash, category);
                return List.of(); // ğŸš« 400 ì—ëŸ¬ ì‹œ ì¬ì‹œë„ X, ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
            }

            RandomSleepUtil.sleep();
        }

        log.info("ì§ë°© ë§¤ë¬¼ ID ìˆ˜ì§‘ ì™„ë£Œ - geohash: {}, category: {}, ì´ ê±´ìˆ˜: {}", geohash, category, itemIds.size());
        return itemIds;
    }

    private void fetchAndSaveItemDetails(Fetcher fetcher, String geohash, PropertyCategory category, List<Long> itemIds) throws Exception {
        log.info("ì§ë°© ë§¤ë¬¼ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ ì‹œì‘ - geohash: {}, category: {}, ì´ ê±´ìˆ˜: {}", geohash, category, itemIds.size());

        FetchConfigDTO config = FetchConfigDTO.zigbangDefaultConfig();

        for (Long itemId : itemIds) {
            try {
                String detailUrl = buildDetailUrl(itemId); // https://api.zigbang.com/v3/items/123456
                String response = fetcher.fetch(detailUrl, config);

                if (response != null && !response.isEmpty()) {
                    saveRawArticle(geohash, category, itemId, response);
                }

                RandomSleepUtil.sleep();

            } catch (Exception e) {
                log.error("ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨ - item_id: {}, ì˜¤ë¥˜: {}", itemId, e.getMessage());
            }
        }

        log.info("ì§ë°© ë§¤ë¬¼ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ - geohash: {}, category: {}", geohash, category);
    }

    private List<Long> parseItemIdsFromResponse(String response) {
        try {
            JsonNode rootNode = objectMapper.readTree(response);
            JsonNode itemsNode = rootNode.get("items");

            List<Long> ids = new ArrayList<>();
            if (itemsNode != null && itemsNode.isArray()) {
                for (JsonNode node : itemsNode) {
                    JsonNode idNode = node.get("item_id");
                    if (idNode != null && idNode.isNumber()) {
                        ids.add(idNode.asLong());
                    }
                }
            }

            return ids;
        } catch (Exception e) {
            log.warn("item_id íŒŒì‹± ì‹¤íŒ¨: {}", e.getMessage());
            return List.of();
        }
    }

    private void saveRawArticle(String geohash, PropertyCategory category, Long itemId, String response) {
        try {
            JsonNode rootNode = objectMapper.readTree(response);
            JsonNode itemNode = rootNode.get("item");

            ZigBangArticle article = new ZigBangArticle();
            article.create(itemId.toString(), geohash, category, itemNode.toString());
            articleRepo.save(article);

            log.info("ì§ë°© ë§¤ë¬¼ ìƒì„¸ë°ì´í„° ì €ì¥ ì™„ë£Œ - geohash: {}, item_id: {}, category: {}", geohash, itemId, category);

        } catch (Exception e) {
            log.error("ì§ë°© ë§¤ë¬¼ ì €ì¥ ì‹¤íŒ¨ - geohash: {}, item_id: {}, ì˜¤ë¥˜: {}", geohash, itemId, e.getMessage());
        }
    }

    private boolean checkHasMore(String response) {
        try {
            Map<String, Object> jsonMap = objectMapper.readValue(response, Map.class);
            return Boolean.TRUE.equals(jsonMap.get("hasNext"));
        } catch (Exception e) {
            return false;
        }
    }

    private boolean isAlreadyCompleted(String geohash, PropertyCategory category) {
        return crawlRepo.findById(ZigBangCrawl.buildId(geohash, category))
                .map(c -> c.getStatus() == CrawlStatus.COMPLETED)
                .orElse(false);
    }

    private void updateCrawlComplete(String geohash, PropertyCategory category) {
        crawlRepo.findById(ZigBangCrawl.buildId(geohash, category))
                .map(c -> c.updateStatus(CrawlStatus.COMPLETED))
                .ifPresent(c -> crawlRepo.save(c));
    }

    private void updateCrawlError(String geohash, PropertyCategory category, String message) {
        ZigBangCrawl crawl = crawlRepo.findById(ZigBangCrawl.buildId(geohash, category))
                .orElse(ZigBangCrawl.create(geohash, category));

        crawlRepo.save(crawl.errorWithLog(message, 1000, CrawlStatus.FAILED));
    }

    public String buildListUrl(PropertyCategory category, String geohash) {
        return shared.buildListUrl(category, geohash);
    }

    public String buildDetailUrl(Long itemId) {
        return shared.buildDetailUrl(itemId);
    }

}